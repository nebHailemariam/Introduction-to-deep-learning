{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSLkT0qL3jgl"
   },
   "source": [
    "# HW4P1: Language Modelling\n",
    "\n",
    "Welcome to the final part 1 hw of this course. This is the only part 1 in which you have PyTorch training (Yay). You will be working on training language models and evaluating them on the task of prediction and generation.<br>\n",
    "The model which you will be coding in this HW very similar to the Speller module from HW4P2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB2bOV3bzYLR"
   },
   "source": [
    "# Get modules and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33919,
     "status": "ok",
     "timestamp": 1728062909445,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "r4_-qG9rSULt",
    "outputId": "db9324aa-b2d4-488f-d703-9703531e05c9"
   },
   "outputs": [],
   "source": [
    "!pip install torchsummaryX==1.1.0\n",
    "!pip install wandb --quiet\n",
    "!pip install matplotlib\n",
    "\n",
    "!pip install transformers -U\n",
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728062909445,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "RnrUvEIC5i5j"
   },
   "outputs": [],
   "source": [
    "# TODO: Import drive if you are using Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728062909445,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "OLRIdtGWYdyy",
    "outputId": "667c366b-851f-4bf0-8af5-0266faced1bd"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1728062910994,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "VNTfP7QDYkOP",
    "outputId": "ceab1f2b-f9ff-4b8b-a1b0-7ba31aeb4c61"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728062910995,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "YGSU5ii-Y2WF",
    "outputId": "d5c16d1f-409f-4d44-cc2a-8f10a315183f"
   },
   "outputs": [],
   "source": [
    "ls drive/MyDrive/IDL.Fall2024/HWs/HW4/HW4P1/handout/hw4p1_handout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728062910995,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "QZNwme4320LW",
    "outputId": "3f3a0422-9907-46ab-bd63-5634f191dd71"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "path = \"YOUR_PATH\"# \"YOUR_PATH\" # TODO: Add path to handout. For example D:/IDL/hw4/hw4p1_handout/handout\n",
    "sys.path.append(path)\n",
    "%cd {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INh9p3v3zbF_"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10437,
     "status": "ok",
     "timestamp": 1728062921429,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "oxiZ42B4SwQ-",
    "outputId": "33545304-43af-49e7-ea35-81b6954c27b4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torchsummaryX\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import gc\n",
    "import glob\n",
    "import wandb\n",
    "import yaml\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# Importing necessary modules from hw4\n",
    "from hw4p1.tests_hw4 import get_prediction_nll, make_generation_text\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: \", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdG352aFYdyz"
   },
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1728062921429,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "9D39sk7AYdy0",
    "outputId": "28bd7ec4-36fd-456f-b9e4-e6aa601c22dc"
   },
   "outputs": [],
   "source": [
    "# Define the vocabulary. Try printing and see\n",
    "VOCAB = [\n",
    "   \"<sos>\", \"<eos>\",\n",
    "    \"A\",   \"B\",    \"C\",    \"D\",\n",
    "    \"E\",   \"F\",    \"G\",    \"H\",\n",
    "    \"I\",   \"J\",    \"K\",    \"L\",\n",
    "    \"M\",   \"N\",    \"O\",    \"P\",\n",
    "    \"Q\",   \"R\",    \"S\",    \"T\",\n",
    "    \"U\",   \"V\",    \"W\",    \"X\",\n",
    "    \"Y\",   \"Z\",    \"'\",    \" \", \"<pad>\"\n",
    "]\n",
    "\n",
    "VOCAB_MAP = {VOCAB[i]:i for i in range(0, len(VOCAB))}\n",
    "# We have also included <sos> and <eos> in the vocabulary for you\n",
    "# However in real life, you include it explicitly if not provided\n",
    "PAD_TOKEN =  VOCAB_MAP[\"<pad>\"]\n",
    "SOS_TOKEN = VOCAB_MAP[\"<sos>\"]\n",
    "EOS_TOKEN = VOCAB_MAP[\"<eos>\"]\n",
    "\n",
    "print(f\"Length of Vocabulary    : {len(VOCAB)}\")\n",
    "print(f\"VOCAB                   : {VOCAB}\")\n",
    "print(f\"PAD_TOKEN               : {PAD_TOKEN}\")\n",
    "print(f\"SOS_TOKEN               : {SOS_TOKEN}\")\n",
    "print(f\"EOS_TOKEN               : {EOS_TOKEN}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"dataset/train-clean-100/transcripts.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15675,
     "status": "ok",
     "timestamp": 1728062937092,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "YDma9y0pYdy0"
   },
   "outputs": [],
   "source": [
    "# Add start token and end token\n",
    "transcripts  = []\n",
    "transcripts = [np.array([i for i in row['transcripts'].replace(\"<sos>\", \"\").replace(\"<eos>\", \"\") ]) for index, row in df.iterrows()]\n",
    "dataset = [[VOCAB_MAP[char] for char in transcript] for transcript in transcripts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCIVNrUqYdy0"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "jW-YAD9b7FoC",
    "outputId": "f3bd0b98-f829-4471-c416-91aaa13a90a2"
   },
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "###### Dataloader Configuration -------------------------------------------------\n",
    "batch_size: 64          # Number of samples per batch during training\n",
    "sequence_length : 500    # Maximum sequence length for input data\n",
    "shuffle : True           # Whether to shuffle the data at the beginning of each epoch\n",
    "drop_last : True        # If True, drops the last incomplete batch if dataset size is not divisible by batch_size\n",
    "\n",
    "###### Model Architecture Configuration ----------------------------------------\n",
    "weight_initialization : \"kaiming_normal\"  # Method for weight initialization. Options: 'kaiming_normal' or 'None' for default initialization\n",
    "ff : 2048                               # Size of the feed-forward hidden layer in Transformer (typically larger than d_model)\n",
    "d_model : 512                           # Dimensionality of model embeddings (size of input/output in multi-head attention)\n",
    "num_layers: 2                           # Number of Transformer decoder layers (stacked)\n",
    "num_heads: 2                            # Number of heads in multi-head attention mechanism\n",
    "dropout: 0.1                            # Dropout rate applied during training\n",
    "max_length: 1000                        # Maximum input sequence length (useful for positional encoding)\n",
    "\n",
    "###### Optimizer Configuration -------------------------------------------------\n",
    "learning_rate: 0.0005                   # Initial learning rate for the optimizer\n",
    "optimizer: \"AdamW\"                       # Optimizer used for training. Options: 'Adam' or 'AdamW'\n",
    "\n",
    "###### Scheduler Configuration -------------------------------------------------\n",
    "scheduler: \"CosineAnnealing\"            # Learning rate scheduler type. Options: 'Cosine', 'ReduceLR', 'CosineAnnealing'\n",
    "\n",
    "# If 'ReduceLROnPlateau' scheduler is chosen:\n",
    "factor: 0.5                             # Factor by which the learning rate is reduced when a plateau is encountered (used for 'ReduceLROnPlateau')\n",
    "patience: 1                             # Number of epochs with no improvement before reducing the learning rate (used for 'ReduceLROnPlateau')\n",
    "\n",
    "###### Experiment Configuration ------------------------------------------------\n",
    "num_epochs: 100                         # Total number of epochs for training the model\n",
    "\n",
    "TA: \"Name\"                              # Placeholder for the name of the teaching assistant or person running the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "SOaoAvAcYdy0"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "UlMTepZGYdy0",
    "outputId": "2440bef9-c291-4247-d356-e710c29f89f1"
   },
   "outputs": [],
   "source": [
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "ulFnR3t8Ydy0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHjYhXAOzkrP"
   },
   "source": [
    "# Custom DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "class DataLoaderForLanguageModeling(torch.utils.data.DataLoader): # Inherit from torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    # TODO: You can probably add more parameters as well. Eg. sequence length\n",
    "    def __init__(self, dataset, batch_size, sequence_length=3, shuffle= True, drop_last= False):\n",
    "\n",
    "        # If you remember, these are the standard things which you give while defining a dataloader.\n",
    "        # Now you are just customizing your dataloader\n",
    "        self.dataset    = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.drop_last  = drop_last\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        # TODO: Shuffle data if shuffle is True\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.dataset)\n",
    "\n",
    "        # TODO: Concatenate articles drop extra words that won't fit into a full batch\n",
    "        self.dataset = np.concatenate(self.dataset)\n",
    "        self.num_batches =  int(np.ceil(len(self.dataset) / (self.sequence_length * self.batch_size)))\n",
    "\n",
    "        if self.drop_last:\n",
    "            self.num_batches -= 1\n",
    "        else:\n",
    "            # Pad the last target sequence with EOS_TOKEN to ensure it has the same length as the other target sequences\n",
    "            pad_width = (self.num_batches * self.sequence_length * self.batch_size) - len(self.dataset) + 1\n",
    "            self.dataset = np.pad(self.dataset, (0, pad_width), mode='constant', constant_values=PAD_TOKEN)\n",
    "\n",
    "    def __len__(self):\n",
    "        # What output do you get when you print len(loader)? You get the number of batches\n",
    "        # Your dataset has (579, ) articles and each article has a specified amount of words.\n",
    "        # You concatenate the dataset and then batch parts of it according to the sequence length\n",
    "        # TODO: return the number of batches\n",
    "        # If you are using variable sequence_length, the length might not be fixed\n",
    "\n",
    "        return self.num_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        # TODO: Divide the concetenated dataset into inputs and targets. How do they vary?\n",
    "        divisible_len = self.num_batches * self.sequence_length * self.batch_size\n",
    "\n",
    "        input_dataset = self.dataset[:divisible_len]\n",
    "        target_dataset = self.dataset[1:divisible_len+1]\n",
    "\n",
    "        # TODO: Reshape the inputs and targets into batches (think about the final shape)\n",
    "        input_dataset = input_dataset.reshape(self.num_batches, self.batch_size, self.sequence_length)\n",
    "        target_dataset = target_dataset.reshape(self.num_batches, self.batch_size, self.sequence_length)\n",
    "\n",
    "        # TODO: Loop though the batches and yield the input and target according to the sequence length\n",
    "        batch_idx = 0\n",
    "        while batch_idx < self.num_batches:\n",
    "            input_batch   = input_dataset[batch_idx,:,:]\n",
    "            target_batch = target_dataset[batch_idx,:,:]\n",
    "            batch_idx += 1\n",
    "            yield input_batch, target_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728062937093,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "gH_fPT-fYdy1"
   },
   "outputs": [],
   "source": [
    "class updated_DataLoaderForLanguageModeling(torch.utils.data.DataLoader): # Inherit from torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    # TODO: You can probably add more parameters as well. Eg. sequence length\n",
    "    def __init__(self, dataset, batch_size, sequence_length=3, shuffle= True, drop_last= False):\n",
    "\n",
    "        # If you remember, these are the standard things which you give while defining a dataloader.\n",
    "        # Now you are just customizing your dataloader\n",
    "        self.dataset    = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.drop_last  = drop_last\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # What output do you get when you print len(loader)? You get the number of batches\n",
    "        # Your dataset has (579, ) articles and each article has a specified amount of words.\n",
    "        # You concatenate the dataset and then batch parts of it according to the sequence length\n",
    "        # TODO: return the number of batches\n",
    "        # If you are using variable sequence_length, the length might not be fixed\n",
    "\n",
    "        dataset_len = sum([len(i) for i in self.dataset])\n",
    "        num_batches =  int(np.ceil(dataset_len / (self.sequence_length * self.batch_size)))\n",
    "\n",
    "        if self.drop_last:\n",
    "            num_batches -= 1\n",
    "        return num_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        # TODO: Shuffle data if shuffle is True\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.dataset)\n",
    "\n",
    "        # TODO: Concatenate articles drop extra words that won't fit into a full batch\n",
    "        self.concatenated_dataset = np.concatenate(self.dataset)\n",
    "        self.num_batches =  int(np.ceil(len(self.concatenated_dataset) / (self.sequence_length * self.batch_size)))\n",
    "\n",
    "        if self.drop_last:\n",
    "            self.num_batches -= 1\n",
    "        else:\n",
    "            # Pad the last target sequence with EOS_TOKEN to ensure it has the same length as the other target sequences\n",
    "            pad_width = (self.num_batches * self.sequence_length * self.batch_size) - len(self.concatenated_dataset) + 1\n",
    "            self.concatenated_dataset = np.pad(self.concatenated_dataset, (0, pad_width), mode='constant', constant_values=PAD_TOKEN)\n",
    "\n",
    "        # TODO: Divide the concetenated dataset into inputs and targets. How do they vary?\n",
    "        divisible_len = self.num_batches * self.sequence_length * self.batch_size\n",
    "\n",
    "        input_dataset = self.concatenated_dataset[:divisible_len]\n",
    "        target_dataset = self.concatenated_dataset[:divisible_len]\n",
    "\n",
    "        # TODO: Reshape the inputs and targets into batches (think about the final shape)\n",
    "        input_dataset = input_dataset.reshape(self.num_batches, self.batch_size, self.sequence_length)\n",
    "        target_dataset = target_dataset.reshape(self.num_batches, self.batch_size, self.sequence_length)\n",
    "\n",
    "        # TODO: Loop though the batches and yield the input and target according to the sequence length\n",
    "        batch_idx = 0\n",
    "        while batch_idx < self.num_batches:\n",
    "            input_batch   = input_dataset[batch_idx,:,:]\n",
    "            target_batch = target_dataset[batch_idx,:,:]\n",
    "            batch_idx += 1\n",
    "            input_batch = np.concatenate([np.zeros((input_batch.shape[0], 1)).astype(np.int64), input_batch], axis=1)\n",
    "            target_batch = np.concatenate([target_batch, np.ones((target_batch.shape[0], 1)).astype(np.int64)], axis=1)\n",
    "            yield input_batch, target_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1728062937979,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "t7IyJOYqYdy1"
   },
   "outputs": [],
   "source": [
    "dl = DataLoaderForLanguageModeling(\n",
    "    dataset     = dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = config['shuffle'],\n",
    "    drop_last   = config['drop_last'],\n",
    "    sequence_length=config['sequence_length']\n",
    "    # Input Extra parameters here if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728062937979,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "fBZSzmy10M9M",
    "outputId": "8a58531b-0518-4e98-904a-80552a244bcd"
   },
   "outputs": [],
   "source": [
    "# Some sanity checks\n",
    "\n",
    "inputs, targets = next(iter(dl))\n",
    "print(inputs.shape, targets.shape)\n",
    "\n",
    "for x, y in dl:\n",
    "    print(\"x: \", [VOCAB[i] for i in x[0, :]])\n",
    "    print(\"y: \", [VOCAB[i] for i in y[0, :]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728062937979,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "nM7gQtZqYdy1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728062937979,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "x5znxQhLSwRC",
    "outputId": "f32f514d-84bd-4806-eddb-bef1011147fc"
   },
   "outputs": [],
   "source": [
    "# Loading the fixtures for validation and test - prediction\n",
    "fixtures_pred       = np.load('fixtures/prediction.npz')        # validation\n",
    "fixtures_pred_test  = np.load('fixtures/prediction_test.npz')   # test\n",
    "\n",
    "print(\"Validation shapes    : \", fixtures_pred['inp'].shape, fixtures_pred['out'].shape)\n",
    "print(\"Test shapes          : \", fixtures_pred_test['inp'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728062937980,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "Pes7mCr5WdAw",
    "outputId": "b6193ced-fb2b-423f-95b6-d3f8be90ffbb"
   },
   "outputs": [],
   "source": [
    "# Loading the test fixtures for generation\n",
    "fixtures_gen_test   = np.load('fixtures/generation_test.npz')   # test\n",
    "\n",
    "print(\"Test Gen Shapes          :\", fixtures_gen_test['inp'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728062937980,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "jO_Qt7O6rL8L"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example Prediction Dev Input and Output\n",
    "# Optional TODO: You can try printing a few samples from the validation set which has both inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcWU0YlnzmVM"
   },
   "source": [
    "# Causal Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7wwkDXlV3xf"
   },
   "source": [
    "Causal language models predict the probability of a word based on the preceding words in the sentence. This differs from bidirectional models, which consider both previous and following context. Here, we use a Transformer-based decoder, leveraging its attention mechanism to focus only on earlier parts of the sequence to predict the next word. This type of modeling is suitable for tasks such as text generation where the sequence order is crucial.\n",
    "\n",
    "\n",
    "**Link to HuggingFace Documentation**: [Causal Language Model](https://huggingface.co/docs/transformers/en/tasks/language_modeling)\n",
    "\n",
    "The following image can be a helpful aid in visualizing the flow of information in a causal language model, highlighting how each word in a sequence is used to predict the next word.\n",
    "\n",
    "<img src=\"https://github.com/christianversloot/machine-learning-articles/blob/main/images/causal-1024x445.png?raw=true\" width=\"60%\">\n",
    "\n",
    "This figure shows three matrices: the attention scores between sequence elements, the causal mask with zeros allowing attention and negative infinity blocking future attention, and the resultant matrix after applying the causal mask. The negative infinity values in the causal mask prevent the model from using future tokens in its predictions, reinforcing the sequence's order. This visualization shows how transformers can be used for causal language modeling where future input information must not influence current predictions.\n",
    "\n",
    "<img src=\"https://github.com/christianversloot/machine-learning-articles/raw/main/images/Diagram-20-1024x282.png\" width=\"80%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dps6lGqiYdy1"
   },
   "source": [
    "# Masking Functions in Attention\n",
    "\n",
    "In sequence models, particularly with Transformers, masks are crucial for managing padding and controlling the flow of information during attention. These functions help create masks for different purposes in sequence modeling. Below is a brief explanation of each mask:\n",
    "\n",
    "## 1. `create_mask_1`: Mask to Identify Non-Padding Positions\n",
    "\n",
    "```python\n",
    "def create_mask_1(padded_input, input_lengths=None, pad_idx=None)\n",
    "```  \n",
    "\n",
    "\n",
    "## Purpose:\n",
    "This function generates a mask to identify **non-padding positions** in a padded input sequence. It marks positions with 1 if they are actual data points and 0 if they are padding tokens.\n",
    "\n",
    "## Usage:\n",
    "- **Input:**\n",
    "  - `padded_input`: Tensor of shape `(N, T, ...)` or `(N, T)` where `N` is batch size and `T` is sequence length.\n",
    "  - `input_lengths`: (Optional) Actual lengths of each sequence before padding.\n",
    "  - `pad_idx`: (Optional) Index representing the padding token.\n",
    "\n",
    "- **Output:**\n",
    "  - A mask of shape `(N, T, 1)` where non-padding positions are marked with 1 and padding positions are marked with 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728062937980,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "v49yRYF7Ydy1"
   },
   "outputs": [],
   "source": [
    "def create_mask_1(padded_input, input_lengths=None, pad_idx=None):\n",
    "    \"\"\" Create a mask to identify non-padding positions.\n",
    "\n",
    "    Args:\n",
    "        padded_input: The input tensor with padding, shape (N, T, ...) or (N, T).\n",
    "        input_lengths: Optional, the actual lengths of each sequence before padding, shape (N,).\n",
    "        pad_idx: Optional, the index used for padding tokens.\n",
    "\n",
    "    Returns:\n",
    "        A mask tensor with shape (N, T, 1), where non-padding positions are marked with 1 and padding positions are marked with 0.\n",
    "    \"\"\"\n",
    "\n",
    "    assert input_lengths is not None or pad_idx is not None\n",
    "\n",
    "    # Create a mask based on input_lengths\n",
    "    if input_lengths is not None:\n",
    "        N = padded_input.size(0)        # padded_input : (N x T x ...)\n",
    "        non_pad_mask = padded_input.new_ones(padded_input.size()[:-1])  # (N x T)\n",
    "\n",
    "        # Set the mask to 0 for padding positions or pad_idx\n",
    "        for i in range(N):\n",
    "\n",
    "            non_pad_mask[i, input_lengths[i]:] = 0 if pad_idx is None  else pad_idx\n",
    "\n",
    "    elif pad_idx is not None:             # padded_input : N x T\n",
    "\n",
    "        assert padded_input.dim() == 2\n",
    "\n",
    "        # Create a mask where non-padding positions are marked with 1 and padding positions are marked with 0\n",
    "        non_pad_mask = padded_input.ne(pad_idx).float()\n",
    "\n",
    "    return non_pad_mask.unsqueeze(-1)   # unsqueeze(-1) for broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9pf61cCYdy2"
   },
   "source": [
    "## 2. `create_mask_2`: Mask for Preventing Attention to Subsequent Positions\n",
    "\n",
    "\n",
    "```python\n",
    "def create_mask_2(seq, pad_idx=None)\n",
    "```\n",
    "\n",
    "\n",
    "## Purpose:\n",
    "This function creates a **subsequent mask** that prevents attention from attending to future positions in the sequence. It ensures that each position can only attend to previous positions (as in causal language modeling).\n",
    "\n",
    "## Usage:\n",
    "- **Input:**\n",
    "  - `seq`: Tensor of shape `(batch_size, sequence_length)` representing the input sequence.\n",
    "  - `pad_idx`: (Optional) Padding index for masking padding positions.\n",
    "\n",
    "- **Output:**\n",
    "  - A mask of shape `(batch_size, sequence_length, sequence_length)` where the upper triangular portion is filled with 1s to prevent attention to future positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728062937980,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "L3BNp-6CYdy2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_mask_2(seq, pad_idx=None):\n",
    "    \"\"\" Create a mask to prevent positions from attending to subsequent positions.\n",
    "\n",
    "    Args:\n",
    "        seq: The input sequence tensor, shape (batch_size, sequence_length).\n",
    "\n",
    "    Returns:\n",
    "        A mask tensor with shape (batch_size, sequence_length, sequence_length),\n",
    "            where positions are allowed to attend to previous positions but not to subsequent positions.\n",
    "    \"\"\"\n",
    "\n",
    "    sz_b, len_s = seq.size()\n",
    "\n",
    "    # Create an upper triangular matrix with zeros on the diagonal and below (indicating allowed positions)\n",
    "    #   and ones above the diagonal (indicating disallowed positions)\n",
    "    subsequent_mask = torch.triu(\n",
    "        torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n",
    "\n",
    "    # Expand the mask to match the batch size, resulting in a mask for each sequence in the batch.\n",
    "    mask = subsequent_mask.unsqueeze(0).expand(sz_b, -1, -1)  # b x ls x ls\n",
    "\n",
    "\n",
    "    ''' Create a mask to ignore padding positions in the key sequence during attention calculation. '''\n",
    "\n",
    "    # Expanding to fit the shape of key query attention matrix.\n",
    "    if pad_idx != None:\n",
    "        len_q = seq.size(1)\n",
    "\n",
    "          # Create a mask where padding positions in the key sequence are marked with 1.\n",
    "        padding_mask  = seq.eq(pad_idx)\n",
    "\n",
    "          # Expand the mask to match the dimensions of the key-query attention matrix.\n",
    "        padding_mask  = padding_mask.unsqueeze(1).expand(-1, len_q, -1)  # b x lq x lk\n",
    "\n",
    "\n",
    "        mask          = (padding_mask + mask).gt(0)\n",
    "\n",
    "    else:\n",
    "        mask = mask.gt(0)\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fItrDEOsYdy2"
   },
   "source": [
    "## Helper function for attention visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728062937980,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "YVNA6gD6Ydy2"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention):\n",
    "    # Function for plotting attention\n",
    "    # You need to get a diagonal plot\n",
    "    plt.clf()\n",
    "    sns.heatmap(attention, cmap='GnBu')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_attention(attention_weights, index=0):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(attention_weights[index].detach().cpu().numpy(), cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Attention Weights for Sample {index}')\n",
    "    plt.xlabel('Key Position')\n",
    "    plt.ylabel('Query Position')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1GobVvxYdy2"
   },
   "source": [
    "# Transformer Decoder Components\n",
    "\n",
    "We will use these components in the Transformer decoder. These include positional encoding, feed-forward networks, scaled dot-product attention, and multi-head attention. Each of these components plays a vital role in processing input sequences and computing attention in the Transformer model.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Positional Encoding (`PositionalEncoding`)**\n",
    "Transformers do not inherently capture the order of sequences, so positional encodings are used to introduce sequence order into the model.\n",
    "\n",
    "- **Purpose**: Adds information about the position of each token in the input sequence.\n",
    "- **Mechanism**: Uses a combination of sine and cosine functions of different frequencies to generate positional encodings.\n",
    "- **Parameters**:\n",
    "  - `projection_size`: The size of the input embeddings (i.e., `d_model`).\n",
    "  - `max_seq_len`: The maximum length of the input sequence (default: 1000).\n",
    "- **Output**: The input embedding enriched with positional information, which is passed through a dropout layer for regularization.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1728063002860,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "wixQHpDaYdy2"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, projection_size, max_seq_len= 1000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout                = torch.nn.Dropout(dropout)\n",
    "\n",
    "        pe              = torch.zeros(max_seq_len, projection_size)\n",
    "        position        = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term        = torch.exp(torch.arange(0, projection_size, 2).float() * (-math.log(10000.0) / projection_size))\n",
    "        pe[:, 0::2]     = torch.sin(position * div_term)\n",
    "        pe[:, 1::2]     = torch.cos(position * div_term)\n",
    "        pe              = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, :x.size(1)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUt8AjEEYdy2"
   },
   "source": [
    "\n",
    "## 2. **Feed-Forward Network (`FeedForward`)**\n",
    "The feed-forward network is a fully connected layer applied independently to each position in the sequence after the attention layers.\n",
    "\n",
    "- **Purpose**: Projects the intermediate representations to a higher-dimensional space and back to the original model dimension.\n",
    "- **Mechanism**: Consists of two linear layers with a GeLU activation function and dropout in between.\n",
    "- **Parameters**:\n",
    "  - `d_model`: The input and output dimensionality of the model.\n",
    "  - `d_ff`: The dimensionality of the hidden layer in the feed-forward network (default: 2048).\n",
    "  - `dropout`: Dropout rate applied after the GeLU activation (default: 0.1).\n",
    "- **Output**: The transformed input sequence passed through two linear transformations with non-linear activation in between.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1728063003222,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "f5UzjJmRYdy2"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    ''' Projection Layer (Fully Connected Layers) '''\n",
    "\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1   = torch.nn.Linear(d_model, d_ff)\n",
    "        self.dropout    = torch.nn.Dropout(dropout)\n",
    "        self.linear_2   = torch.nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply the first linear layer, GeLU activation, and then dropout\n",
    "        x = self.dropout(torch.nn.functional.gelu(self.linear_1(x)))\n",
    "\n",
    "         # Apply the second linear layer to project the dimension back to d_model\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vofvMG5lYdy7"
   },
   "source": [
    "\n",
    "\n",
    "## 3. **Scaled Dot-Product Attention (`ScaledDotProductAttention`)**\n",
    "This module computes the attention score for each query-key pair in the input sequence using the scaled dot-product mechanism.\n",
    "\n",
    "- **Purpose**: To compute attention scores and generate weighted outputs based on the input query, key, and value matrices.\n",
    "- **Mechanism**:\n",
    "  - Calculates the dot product of queries and keys, scales by the square root of the dimension, and applies a softmax to generate attention weights.\n",
    "  - Uses dropout for regularization.\n",
    "- **Parameters**:\n",
    "  - `temperature`: Scaling factor for the dot product.\n",
    "  - `attn_dropout`: Dropout rate for attention weights (default: 0.1).\n",
    "- **Output**: Returns the weighted sum of the values and the attention weights.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1728063003627,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "wMB9Jb45Ydy7"
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(torch.nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature    = temperature                       # Scaling factor for the dot product\n",
    "        self.dropout        = torch.nn.Dropout(attn_dropout)    # Dropout layer for attention weights\n",
    "        self.softmax        = torch.nn.Softmax(dim=-1)           # Softmax layer along the attention dimension\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        # Calculate the dot product between queries and keys.\n",
    "        # attn = torch.bmm(q, k.transpose(1, 2))\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        # Scale the dot product by the temperature.\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            # Apply the mask by setting masked positions to a large negative value.\n",
    "            # This ensures they have a softmax score close to zero.\n",
    "            attn = attn.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        # Apply softmax to obtain attention weights.\n",
    "        attn    = self.softmax(attn)\n",
    "\n",
    "        # Apply dropout to the attention weights.\n",
    "        # Compute the weighted sum of values based on the attention weights.\n",
    "        # output  = torch.bmm(self.dropout(attn), v)\n",
    "        attn = self.dropout(attn)\n",
    "        output = attn @ v\n",
    "\n",
    "        return output, attn # Return the attention output and the attention weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjSRj_hjYdy7"
   },
   "source": [
    "## 4. **Multi-Head Attention (`MultiHeadAttention`)**\n",
    "This module implements multi-head attention, where multiple sets of attention heads are computed in parallel, and their outputs are concatenated.\n",
    "\n",
    "- **Purpose**: To allow the model to jointly attend to different positions in the input sequence from different representation subspaces.\n",
    "- **Mechanism**:\n",
    "  - Projects the input query, key, and value matrices into multiple smaller subspaces (heads).\n",
    "  - Computes scaled dot-product attention for each head in parallel.\n",
    "  - Concatenates the outputs of all heads and applies a final linear transformation to project the result back to the original model dimension.\n",
    "- **Parameters**:\n",
    "  - `n_head`: Number of attention heads.\n",
    "  - `d_model`: Dimensionality of the input and output representations.\n",
    "  - `dropout`: Dropout rate applied to the attention output (default: 0.1).\n",
    "- **Output**: Returns the concatenated output of all attention heads and the averaged attention weights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1728063003627,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "TRa-PPXrYdy7"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    ''' Multi-Head Attention Module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head # Number of attention heads\n",
    "        self.d_k    = d_model // n_head\n",
    "        self.d_v    = d_model // n_head\n",
    "\n",
    "\n",
    "        # Linear layers for projecting the input query, key, and value to multiple heads\n",
    "        self.w_qs   = torch.nn.Linear(d_model, n_head * self.d_k)\n",
    "        self.w_ks   = torch.nn.Linear(d_model, n_head * self.d_k)\n",
    "        self.w_vs   = torch.nn.Linear(d_model, n_head * self.d_v)\n",
    "\n",
    "        torch.nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + self.d_k)))\n",
    "        torch.nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + self.d_k)))\n",
    "        torch.nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + self.d_v)))\n",
    "\n",
    "        # Initialize the weights of the linear layers\n",
    "        self.attention = ScaledDotProductAttention(\n",
    "            temperature=np.power(self.d_k, 0.5), attn_dropout=dropout)\n",
    "\n",
    "        # Final linear layer to project the concatenated outputs of the attention heads back to the model dimension\n",
    "        self.fc = torch.nn.Linear(n_head * self.d_v, d_model)\n",
    "        torch.nn.init.normal_(self.fc.weight)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        # following key, value, query standard computation\n",
    "        d_k, d_v, n_head    = self.d_k, self.d_v, self.n_head\n",
    "        sz_b, len_q, _      = q.size()\n",
    "        sz_b, len_k, _      = k.size()\n",
    "        sz_b, len_v, _      = v.size()\n",
    "\n",
    "        # Project the input query, key, and value to multiple heads\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        # Rearrange the dimensions to group the heads together for parallel processing\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "\n",
    "        # Repeat the mask for each attention head if a mask is provided\n",
    "        if mask is not None:\n",
    "              # print(mask.shape)\n",
    "              mask = mask.unsqueeze(1).repeat(1, n_head, 1, 1)\n",
    "\n",
    "        # Apply scaled dot-product attention to the projected query, key, and value\n",
    "        output, attn    = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # Rearrange the output back to the original order and concatenate the heads\n",
    "        output = output.transpose(1, 2).contiguous().view(sz_b, len_v, -1)\n",
    "\n",
    "        output          = self.dropout(self.fc(output))\n",
    "\n",
    "        attn_weights = attn.mean(dim=(0, 1))\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rlvl41QtYdy7"
   },
   "source": [
    "# Transformer Decoder Layers\n",
    "\n",
    "The `DecoderLayer1`, `DecoderLayer2`, and `DecoderLayer3` are modular components of the Transformer decoder. Each layer is designed to handle a specific function: self-attention, cross-attention, and feed-forward processing.\n",
    "\n",
    "## 1. `DecoderLayer1`: Self-Attention Layer\n",
    "- **Purpose**: Implements self-attention, where the decoder attends to its own inputs, combined with residual connections and layer normalization.\n",
    "- **Components**:\n",
    "  - `MultiHeadAttention`: Applies self-attention to the target sequence.\n",
    "  - `LayerNorm`: Normalizes the output after the residual connection.\n",
    "  - `Dropout`: Regularization to prevent overfitting.\n",
    "\n",
    "## 2. `DecoderLayer2`: Cross-Attention Layer\n",
    "- This layer implements cross-attention, where the decoder attends to the output of an encoder. However, for this homework, we will not use `DecoderLayer2` during the pretraining phase because we do not have an encoder in our setup. We will describe its functionality in part 2 of this homework.\n",
    "\n",
    "## 3. `DecoderLayer3`: Feed-Forward Layer\n",
    "- **Purpose**: Implements a feed-forward neural network for further transformation of the decoder's intermediate representations.\n",
    "- **Components**:\n",
    "  - `FeedForward`: A two-layer fully connected network with non-linearity.\n",
    "  - `LayerNorm`: Applied after the residual connection.\n",
    "  - `Dropout`: Regularization to avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1728063003974,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "5hX2kBrAYdy7"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer1(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        \"\"\"\n",
    "        DecoderLayer (attention and layer norm) in the Transformer architecture.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The number of expected features in the input (embedding dimension).\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_ff (int): Dimension of the feedforward network model.\n",
    "            dropout (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super(DecoderLayer1, self).__init__()\n",
    "\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(num_heads, d_model, dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, attn_mask=None, key_padding_mask=None):\n",
    "        is_inference = not self.self_attn.training\n",
    "\n",
    "        tgt2 = self.layer_norm(tgt)\n",
    "        tgt2, attn_weights = self.self_attn(\n",
    "            tgt2, tgt2, tgt2, attn_mask)\n",
    "\n",
    "        tgt = tgt + self.dropout(tgt2)\n",
    "        return tgt, attn_weights\n",
    "\n",
    "\n",
    "class DecoderLayer3(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        \"\"\"\n",
    "        Feedforward layer with layer normalization in the Transformer decoder.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Embedding dimension.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_ff (int): Dimension of the feedforward network.\n",
    "            dropout (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super(DecoderLayer3, self).__init__()\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt):\n",
    "        tgt2 = self.layer_norm(tgt)\n",
    "        tgt2 = self.ffn(tgt2)\n",
    "        tgt = tgt + self.dropout(tgt2)\n",
    "        return tgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnMbHHLcYdy7"
   },
   "source": [
    "# Causal Language Model\n",
    "\n",
    "This module implements a Transformer-based decoder for causal language modeling (CLM). It consists of several components, including embedding layers, positional encoding, self-attention layers, and feed-forward layers. It supports various generation strategies such as beam search and sampling.\n",
    "\n",
    "### Key Components:\n",
    "- **Embedding Layer**: Converts input tokens into dense vector representations.\n",
    "- **Positional Encoding**: Adds position information to input tokens, helping the model understand the order of tokens.\n",
    "- **Decoder Layers**: Composed of:\n",
    "  - `DecoderLayer1`: Implements self-attention and layer normalization.\n",
    "  - `DecoderLayer3`: Implements a feed-forward network with residual connections.\n",
    "- **Output Linear Layer**: Projects the hidden states to the vocabulary size to generate output probabilities.\n",
    "\n",
    "### Key Methods:\n",
    "- **`forward`**: Runs the input through the decoder layers and generates output probabilities.\n",
    "- **`predict_beam`**: Implements beam search for sequence generation, selecting the most likely sequence.\n",
    "- **`predict_beam_sampling`**: Uses beam search with probabilistic sampling for sequence generation.\n",
    "- **`generate`**: Generates a sequence step-by-step (greedy) for a given input sequence.\n",
    "- **`predict`**: Predicts the next token given the current input.\n",
    "- **`vec2text`**: Converts predicted vectors to human-readable text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1728063089592,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "cebwoorWttWe"
   },
   "outputs": [],
   "source": [
    "# Here comes the main portion of this HW.\n",
    "\n",
    "\n",
    "class CausalLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size=31, d_model=256, num_layers=2, num_heads=2, d_ff=512, dropout=0.1, max_length=1000):\n",
    "\n",
    "        \"\"\"\n",
    "        Decoder module in the Transformer architecture.\n",
    "        Initializes embeddings, multiple decoder layers, and an output linear layer.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary.\n",
    "            d_model (int): The number of expected features in the input (embedding dimension).\n",
    "            num_layers (int): Number of decoder layers.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_ff (int): Dimension of the feedforward network model.\n",
    "            dropout (float): Dropout probability.\n",
    "            max_length (int): Maximum length of input sequences.\n",
    "        \"\"\"\n",
    "\n",
    "        super(CausalLanguageModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx = PAD_TOKEN)\n",
    "\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_length, dropout)\n",
    "        self.num_layers= num_layers\n",
    "        self.dec_layers1 = nn.ModuleList([DecoderLayer1(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dec_layers3 = nn.ModuleList([DecoderLayer3(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "        size = inp.size(1)\n",
    "        key_padding_mask = (inp == PAD_TOKEN)  # padding mask to ignore padded positions in attention computation\n",
    "        attn_mask = create_mask_2(inp, pad_idx=PAD_TOKEN)\n",
    "        key_padding_mask = create_mask_1(inp, pad_idx=PAD_TOKEN)\n",
    "\n",
    "        inp = self.embedding(inp) * math.sqrt(self.embedding.embedding_dim) # ( batch_size, seq_len, d_model )\n",
    "        inp = self.pos_encoder(inp)\n",
    "\n",
    "        # print(attn_mask[0])\n",
    "\n",
    "        attention_weights_list = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            inp, attn_weights = self.dec_layers1[i](inp, attn_mask, key_padding_mask)\n",
    "            inp = self.dec_layers3[i](inp)\n",
    "            attention_weights_list.append(attn_weights)\n",
    "\n",
    "        output = self.fc(self.ln(inp))\n",
    "\n",
    "        stacked_attention_weights = torch.stack(attention_weights_list, dim=0)\n",
    "\n",
    "        return output, stacked_attention_weights\n",
    "\n",
    "\n",
    "\n",
    "    def predict_beam(self, x, timesteps, beam_width=20):\n",
    "        import torch.nn.functional as F\n",
    "        import torch\n",
    "\n",
    "        x = torch.tensor(x).long().to(DEVICE)\n",
    "        batch_size, seq_len = x.shape\n",
    "        vocab_size = self.embedding.weight.shape[0]  # Assuming this is 31\n",
    "\n",
    "        # Initialize beam for each item in the batch\n",
    "        beam = [(torch.zeros(batch_size).to(DEVICE), x, []) for _ in range(beam_width)]\n",
    "\n",
    "        for _ in range(timesteps):  # We only need to predict the remaining timesteps\n",
    "            candidates = []\n",
    "            for log_prob, seq, prob_dists in beam:\n",
    "                with torch.inference_mode():\n",
    "                    y, _ = self.forward(seq)\n",
    "                    last_prob = y[:, -1, :]  # Get last time step output\n",
    "                    prob_dists.append(last_prob)  # Store distribution\n",
    "\n",
    "                    # Apply softmax to convert logits to probabilities\n",
    "                    probs = F.softmax(last_prob, dim=-1)\n",
    "                    top_probs, top_indices = probs.topk(beam_width, dim=-1)\n",
    "\n",
    "                    # Create new candidates\n",
    "                    for i in range(beam_width):\n",
    "                        next_token = top_indices[:, i]\n",
    "                        new_seq = torch.cat((seq, next_token.unsqueeze(1)), dim=1)\n",
    "                        new_prob = log_prob + top_probs[:, i].log()  # Update log prob\n",
    "                        candidates.append((new_prob, new_seq, prob_dists.copy()))\n",
    "\n",
    "            # Select the top `beam_width` candidates for each item in the batch\n",
    "            beam = sorted(candidates, key=lambda x: x[0].mean().item(), reverse=True)[:beam_width]\n",
    "\n",
    "        # Select the best candidate\n",
    "        best_candidate = max(beam, key=lambda x: x[0].mean().item())\n",
    "        log_likelihood, best_seq, best_prob_dists = best_candidate\n",
    "\n",
    "        # Extract only the predicted part, removing the original input\n",
    "        predicted_seq = best_seq[:, seq_len:]\n",
    "        log_likelihood = log_likelihood\n",
    "\n",
    "        return log_likelihood, predicted_seq\n",
    "\n",
    "\n",
    "    def predict_beam_sampling(self, x, timesteps, beam_width=20):\n",
    "        import torch.nn.functional as F\n",
    "        import torch\n",
    "\n",
    "        x = torch.tensor(x).long().to(DEVICE)\n",
    "        batch_size, seq_len = x.shape\n",
    "        vocab_size = self.embedding.weight.shape[0]  # Assuming this is 31\n",
    "\n",
    "        # Initialize beam for each item in the batch\n",
    "        beam = [(torch.zeros(batch_size).to(DEVICE), x, []) for _ in range(beam_width)]\n",
    "\n",
    "        for _ in range(timesteps):  # We only need to predict the remaining timesteps\n",
    "            candidates = []\n",
    "            for log_prob, seq, prob_dists in beam:\n",
    "                with torch.inference_mode():\n",
    "                    y, _ = self.forward(seq)\n",
    "                    last_prob = y[:, -1, :]  # Get last time step output\n",
    "                    prob_dists.append(last_prob)  # Store distribution\n",
    "\n",
    "                    # Apply softmax to convert logits to probabilities\n",
    "                    probs = F.softmax(last_prob, dim=-1)\n",
    "\n",
    "                    # Sample `beam_width` new candidates based on probabilities\n",
    "                    sampled_indices = torch.multinomial(probs, beam_width, replacement=True)\n",
    "                    for i in range(beam_width):\n",
    "                        next_token = sampled_indices[:, i]\n",
    "                        new_seq = torch.cat((seq, next_token.unsqueeze(1)), dim=1)\n",
    "                        # Compute log probabilities of sampled indices\n",
    "                        new_prob = log_prob + probs.gather(1, next_token.unsqueeze(1)).log().squeeze(1)\n",
    "                        candidates.append((new_prob, new_seq, prob_dists.copy()))\n",
    "\n",
    "            # Select the top `beam_width` candidates for each item in the batch\n",
    "            beam = sorted(candidates, key=lambda x: x[0].mean().item(), reverse=True)[:beam_width]\n",
    "\n",
    "        # Select the best candidate\n",
    "        best_candidate = max(beam, key=lambda x: x[0].mean().item())\n",
    "        log_likelihood, best_seq, best_prob_dists = best_candidate\n",
    "\n",
    "        # Extract only the predicted part, removing the original input\n",
    "        predicted_seq = best_seq[:, seq_len:]\n",
    "        log_likelihood = log_likelihood\n",
    "\n",
    "        return log_likelihood, predicted_seq\n",
    "\n",
    "    def predict_nucleus_sampling(self, x, timesteps, p=0.95):\n",
    "        import torch.nn.functional as F\n",
    "        import torch\n",
    "\n",
    "        x = torch.tensor(x).long().to(DEVICE)\n",
    "        batch_size, seq_len = x.shape\n",
    "\n",
    "        # Initialize sequences and log probabilities\n",
    "        seq = x\n",
    "        log_prob = torch.zeros(batch_size).to(DEVICE)\n",
    "        prob_dists = []\n",
    "\n",
    "        for _ in range(timesteps):  # We only need to predict the remaining timesteps\n",
    "            with torch.inference_mode():\n",
    "                y, _ = self.forward(seq)\n",
    "                last_prob = y[:, -1, :]  # Get last time step output\n",
    "                prob_dists.append(last_prob)  # Store distribution\n",
    "\n",
    "                # Apply softmax to convert logits to probabilities\n",
    "                probs = F.softmax(last_prob, dim=-1)\n",
    "\n",
    "                # Sort the probabilities and their corresponding indices\n",
    "                sorted_probs, sorted_indices = torch.sort(probs, descending=True, dim=-1)\n",
    "\n",
    "                # Calculate cumulative probabilities\n",
    "                cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "                # Select indices where cumulative probability <= p\n",
    "                top_p_mask = cumulative_probs <= p\n",
    "                top_p_mask[:, 0] = True  # Ensure at least one token is selected\n",
    "\n",
    "                # Mask out probabilities outside the nucleus (i.e., top-p subset)\n",
    "                top_p_probs = sorted_probs * top_p_mask\n",
    "\n",
    "                # Normalize the probabilities within the top-p set\n",
    "                normalized_top_p_probs = top_p_probs / top_p_probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "                # Sample the next token from the top-p subset\n",
    "                sampled_indices = torch.multinomial(normalized_top_p_probs, 1).squeeze(1)\n",
    "\n",
    "                # Map sampled indices back to the original token space\n",
    "                next_token = sorted_indices.gather(1, sampled_indices.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                # Update sequence with the newly sampled token\n",
    "                seq = torch.cat((seq, next_token.unsqueeze(1)), dim=1)\n",
    "\n",
    "                # Update log probabilities\n",
    "                log_prob = log_prob + probs.gather(1, next_token.unsqueeze(1)).log().squeeze(1)\n",
    "\n",
    "        # Extract only the predicted part, removing the original input\n",
    "        predicted_seq = seq[:, seq_len:]\n",
    "\n",
    "        return log_prob, predicted_seq\n",
    "\n",
    "\n",
    "    def generate(self, x, timesteps):\n",
    "        # Refer to section 1.2.4 to understand this function\n",
    "        # Important Note: We do not draw <eos> from the distribution unlike the writeup\n",
    "\n",
    "        timesteps -= 1\n",
    "        x = torch.tensor(x).long().to(DEVICE)\n",
    "\n",
    "        # TODO: Pass the input sequence through the model\n",
    "        # Obtain the probability distribution\n",
    "        # token_prob_dist  = self.forward(x)\n",
    "\n",
    "        # TODO: Draw the next predicted token from the probability distribution ()\n",
    "        # next_token                              = token_prob_dist[:,-1,:].argmax(dim=-1).unsqueeze(1)\n",
    "        # What would generated_sequence be initialized with?\n",
    "        generated_sequence  = [] # maybe '<sos>'\n",
    "        with torch.inference_mode():\n",
    "            for t in range(timesteps): # Loop through the timesteps\n",
    "\n",
    "                # TODO: Pass the next_token through the model\n",
    "                next_prob_dist, _ = self.forward(x)\n",
    "                # TODO: You will get 1 output. What is the shape of the probability distribution?\n",
    "                dist_shape = next_prob_dist.shape\n",
    "\n",
    "                # TODO: Get the most probable token for the next timestep\n",
    "                next_token = torch.argmax(next_prob_dist[:,-1,:], dim=-1).unsqueeze(1)\n",
    "\n",
    "                x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "                generated_sequence.append(next_token)\n",
    "\n",
    "\n",
    "\n",
    "            generated_sequence = torch.stack(generated_sequence, dim= 1) # keep last timesteps generated words\n",
    "\n",
    "        return generated_sequence.squeeze(-1)\n",
    "\n",
    "\n",
    "    def predict(self, x, timesteps=20):\n",
    "        # Refer to Section 1.2.6 to understand this function\n",
    "\n",
    "\n",
    "        x = torch.tensor(x).long().to(DEVICE)\n",
    "        prob_dists = []  # List to store each output distribution\n",
    "        with torch.inference_mode():\n",
    "            for _ in range(timesteps):\n",
    "                y, _ = self.forward(x)\n",
    "                last_prob = y[:, -1, :]  # Get the last time step output\n",
    "                prob_dists.append(last_prob)\n",
    "\n",
    "                # Use the argmax to select the next token\n",
    "                next_token = last_prob.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "                # Concatenate the predicted token to the input sequence for the next prediction\n",
    "                x = torch.cat((x, next_token), dim=1)\n",
    "\n",
    "\n",
    "        # Stack all collected probability distributions into a tensor\n",
    "\n",
    "        return torch.stack(prob_dists, dim=1)\n",
    "\n",
    "\n",
    "    def vec2text(self, inp, pred):\n",
    "\n",
    "        # batch size, seq leength, vocab\n",
    "\n",
    "        pred = torch.Tensor(pred)\n",
    "\n",
    "        generated_sequence  = []\n",
    "        pred = pred[:2]\n",
    "        inp = inp[:2]\n",
    "        with torch.inference_mode():\n",
    "            for t in range(pred.shape[1]):\n",
    "\n",
    "                next_token = torch.argmax(pred[:, t,:], dim=-1).unsqueeze(1)\n",
    "                generated_sequence.append(next_token)\n",
    "\n",
    "\n",
    "            generated_sequence = torch.stack(generated_sequence, dim= 1).squeeze(-1) # keep last timesteps generated words\n",
    "\n",
    "        # convert to text\n",
    "        generated_texts_test  = make_generation_text(inp, generated_sequence, VOCAB)\n",
    "\n",
    "        return generated_texts_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DelhoytAQWQa"
   },
   "source": [
    "# Model, Loss, Optimizer, and Scheduler Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1728063091017,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "DbHH6zXTSwRa",
    "outputId": "317457b3-dea4-450f-f426-9da3d7a552e2"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = CausalLanguageModel(\n",
    "    vocab_size = len(VOCAB),\n",
    "    d_model    = config['d_model'],\n",
    "    num_layers = config['num_layers'],\n",
    "    num_heads  = config['num_heads'],\n",
    "    d_ff       = config['ff'],\n",
    "    dropout    = config['dropout'],\n",
    "    max_length = config['max_length']\n",
    ").to(DEVICE)\n",
    "\n",
    "# Define the dataloader\n",
    "loader = updated_DataLoaderForLanguageModeling(\n",
    "    dataset=dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    sequence_length=config['sequence_length'],\n",
    "    shuffle=config['shuffle'],\n",
    "    drop_last=config['drop_last']\n",
    ")\n",
    "\n",
    "# Define the criterion (CrossEntropyLoss with label smoothing)\n",
    "criterion = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=PAD_TOKEN,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "# Define the optimizer based on config (Adam or AdamW)\n",
    "if config[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=2e-6\n",
    "    )\n",
    "elif config[\"optimizer\"] == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "if config[\"scheduler\"] == \"ReduceLR\":\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        factor=config[\"factor\"],\n",
    "        patience=config[\"patience\"],\n",
    "        min_lr=1E-8,\n",
    "        verbose=True\n",
    "    )\n",
    "elif config[\"scheduler\"] == \"CosineAnnealing\":\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config[\"num_epochs\"],\n",
    "        eta_min=1E-8\n",
    "    )\n",
    "\n",
    "# Define the scaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Print the model architecture and parameter summary\n",
    "print(model)\n",
    "\n",
    "# Optionally, if you want to summarize the model, make sure `torchsummaryX` is installed\n",
    "summary = torchsummaryX.summary(model.to(DEVICE), x=torch.tensor(inputs).to(DEVICE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728063091017,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "-87nvdsVYdy8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlWF_bpLznup"
   },
   "source": [
    "\n",
    "\n",
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728063091017,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "VmYwq61mYdy8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1728063755010,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# Unlike all the P2s, we are using a Trainer class for this HW.\n",
    "# Many researchers also use classes like this for training. You may have encountered them in your project as well.\n",
    "# You dont have to complete everything in this class, you only need to complete the train function.\n",
    "# However, its good to go through the code and see what it does.\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loader, optimizer, criterion, scheduler, scaler, max_epochs= 1, run_id= 'exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model      = model\n",
    "        self.loader     = loader\n",
    "        self.optimizer  = optimizer\n",
    "        self.criterion  = criterion\n",
    "        self.scheduler  = scheduler\n",
    "        self.scaler     = scaler\n",
    "\n",
    "        self.train_losses           = []\n",
    "        self.val_losses             = []\n",
    "        self.prediction_probs       = []\n",
    "        self.prediction_probs_test  = []\n",
    "        self.generated_texts_test   = []\n",
    "        self.generated_texts_test_beam = []\n",
    "        self.generated_texts_test_beam_random = []\n",
    "\n",
    "        self.log_likelihood_beam = []\n",
    "        self.log_likelihood_beam_random = []\n",
    "\n",
    "        self.epochs                 = 0\n",
    "        self.max_epochs             = max_epochs\n",
    "        self.run_id                 = run_id\n",
    "\n",
    "\n",
    "    def calculate_loss(self, out, target):\n",
    "        # output: (B, T, Vocab_size) - probability distributions\n",
    "        # target: (B, T)\n",
    "        # Read the documentation of CrossEntropyLoss and try to understand how it takes inputs\n",
    "\n",
    "        # Tip: If your target is of shape (B, T) it means that you have B batches with T words.\n",
    "        # Tip: What is the total number of words in this batch?\n",
    "        # Tip: Crossentropy calculates the loss between a label and its probability distribution.\n",
    "\n",
    "        out     = out.reshape(-1, len(VOCAB)) # TODO\n",
    "        targets = target.reshape(-1) # TODO\n",
    "        loss    = self.criterion(out, targets)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        self.model.train() # set to training mode\n",
    "        self.model.to(DEVICE)\n",
    "        epoch_loss  = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_num, (inputs, targets) in enumerate(tqdm(self.loader)):\n",
    "\n",
    "            # TODO: Complete the loop. You should be able to complete this without any helper comments after 3 HWs\n",
    "            # Tip: Use Mixed Precision Training\n",
    "            # For loss calculation, use the calculate_loss function. You need to complete it before using.\n",
    "\n",
    "            inputs = torch.tensor(inputs).long().to(DEVICE)\n",
    "            targets = torch.tensor(targets).long().to(DEVICE)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out, attn_weights  = self.model(inputs)\n",
    "                loss = self.calculate_loss(out=out, target=targets)\n",
    "\n",
    "            loss_item = loss.item()\n",
    "            epoch_loss += loss_item\n",
    "\n",
    "            self.scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "            self.scaler.step(self.optimizer) # This is a replacement for optimizer.step()\n",
    "            self.scaler.update() # This is something added just for FP16\n",
    "            \n",
    "\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN] \\tEpoch [%d/%d] \\tLoss: %.4f \\tLr: %.6f'\n",
    "                    % (self.epochs, self.max_epochs, epoch_loss, self.optimizer.param_groups[0]['lr']))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "        return (epoch_loss, self.optimizer.param_groups[0]['lr'], attn_weights)\n",
    "\n",
    "\n",
    "\n",
    "    def test(self): # Don't change this function\n",
    "\n",
    "        self.model.eval() # set to eval mode\n",
    "        prediction_probs     = self.model.predict(fixtures_pred['inp']).detach().cpu().numpy() # get predictions\n",
    "        self.prediction_probs.append(prediction_probs)\n",
    "\n",
    "        generated_indexes_test   = self.model.generate(fixtures_gen_test['inp'], 30).detach().cpu().numpy() # generated predictions for 10 words\n",
    "\n",
    "        nll                   = get_prediction_nll(prediction_probs, fixtures_pred['out'])\n",
    "\n",
    "        log_likelihood, predicted_beam_indices = self.model.predict_beam(fixtures_gen_test['inp'], 30)\n",
    "        predicted_beam_indices = predicted_beam_indices.detach().cpu().numpy()\n",
    "        log_likelihood_random, predicted_beam_random_indices = self.model.predict_beam_sampling(fixtures_gen_test['inp'], 30)\n",
    "        predicted_beam_random_indices = predicted_beam_random_indices.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        self.log_likelihood_beam.append(log_likelihood)\n",
    "        self.log_likelihood_beam_random.append(log_likelihood_random)\n",
    "#         print(predicted_beam_indices.shape)\n",
    "#         print(generated_indexes_test.shape)\n",
    "\n",
    "        predicted_beam_text = make_generation_text(fixtures_gen_test['inp'], predicted_beam_indices, VOCAB)\n",
    "        predicted_beam_random_text = make_generation_text(fixtures_gen_test['inp'], predicted_beam_random_indices, VOCAB)\n",
    "\n",
    "        generated_texts_test  = make_generation_text(fixtures_gen_test['inp'], generated_indexes_test, VOCAB)\n",
    "\n",
    "        self.val_losses.append(nll)\n",
    "\n",
    "        self.generated_texts_test.append(generated_texts_test)\n",
    "        self.generated_texts_test_beam.append(predicted_beam_text)\n",
    "        self.generated_texts_test_beam_random.append(predicted_beam_random_text)\n",
    "\n",
    "        # generate predictions for test data\n",
    "        prediction_probs_test = self.model.predict(fixtures_pred_test['inp']).detach().cpu().numpy() # get predictions\n",
    "        self.prediction_probs_test.append(prediction_probs_test)\n",
    "\n",
    "        print('[VAL] \\tEpoch [%d/%d] \\tLoss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, nll))\n",
    "\n",
    "        return nll\n",
    "\n",
    "\n",
    "    def save(self): # Don't change this function\n",
    "\n",
    "        model_path = os.path.join('hw4p1/experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()}, model_path)\n",
    "        np.save(os.path.join('hw4p1/experiments', self.run_id, 'prediction-probs-{}.npy'.format(self.epochs)), self.prediction_probs[-1])\n",
    "        np.save(os.path.join('hw4p1/experiments', self.run_id, 'prediction-probs-test-{}.npy'.format(self.epochs)), self.prediction_probs_test[-1])\n",
    "\n",
    "        with open(os.path.join('hw4p1/experiments', self.run_id, 'generated-texts-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_texts_test[-1])\n",
    "\n",
    "\n",
    "        #########################################\n",
    "        generated_beam = []\n",
    "\n",
    "        for line, score  in zip(self.generated_texts_test_beam[-1].split(\"\\n\"), self.log_likelihood_beam[-1]):\n",
    "            generated_beam += [line +  f\"\\t Score:{score.item():0.4f}\"]\n",
    "\n",
    "\n",
    "        with open(os.path.join('hw4p1/experiments', self.run_id, 'generated-texts-beam-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(\"\\n\".join(generated_beam))\n",
    "\n",
    "\n",
    "        generated_beam = []\n",
    "\n",
    "        for line, score  in zip(self.generated_texts_test_beam_random[-1].split(\"\\n\"), self.log_likelihood_beam_random[-1]):\n",
    "            generated_beam += [line +  f\"\\t Score:{score.item():0.4f}\"]\n",
    "\n",
    "\n",
    "        with open(os.path.join('hw4p1/experiments', self.run_id, 'generated-texts-beam-random-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(\"\\n\".join(generated_beam))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1728063755392,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "2HCVG5YISwRW",
    "outputId": "52336d53-a2f3-4303-d2b7-aaf2a91684ca"
   },
   "outputs": [],
   "source": [
    "# Dont change this cell\n",
    "\n",
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./hw4p1/experiments'):\n",
    "    os.mkdir('./hw4p1/experiments')\n",
    "os.mkdir('./hw4p1/experiments/%s' % run_id)\n",
    "print(\"Saving models, prediction prbabilities, and generated texts to ./hw4p1/experiments/%s\" % run_id)\n",
    "\n",
    "# The object of the Trainer class takes in everything\n",
    "trainer = Trainer(\n",
    "    model       = model,\n",
    "    loader      = loader,\n",
    "\n",
    "    optimizer   = optimizer,\n",
    "    criterion   = criterion,\n",
    "    scheduler   = scheduler,\n",
    "    scaler      = scaler,\n",
    "    max_epochs  = config['num_epochs'],\n",
    "    run_id      = run_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728063755769,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "K1IkFEgHYdy8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dfrf1FoSoAI0"
   },
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 5866,
     "status": "ok",
     "timestamp": 1728063761633,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "91s_RQaQYdy8",
    "outputId": "9794be29-cc17-4e81-83b7-b0a9b7c4137b"
   },
   "outputs": [],
   "source": [
    "# Use wandb? Resume Training?\n",
    "USE_WANDB = True\n",
    "RESUME_LOGGING = False\n",
    "\n",
    "# Create your wandb run\n",
    "\n",
    "run_name = '{}_d_model:_{}_ff:_{}'.format(\n",
    "    config['TA'],\n",
    "    config['d_model'],\n",
    "    config['ff'],\n",
    "\n",
    ")\n",
    "\n",
    "if USE_WANDB:\n",
    "\n",
    "    wandb.login(key=\"2ed342afb6f5e8a1ef3c71c50f0f4ecb7a2f6dbe\") # IDL course key, please don't change\n",
    "\n",
    "    if RESUME_LOGGING:\n",
    "        run_id = ''\n",
    "        run = wandb.init(\n",
    "            settings=wandb.Settings(symlink=False),\n",
    "            id     = run_id, ### Insert specific run id here if you want to resume a previous run\n",
    "            resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "            project = \"hw4p1-f24\", ### Project should be created in your wandb account\n",
    "        )\n",
    "    else:\n",
    "        run = wandb.init(\n",
    "            name    = run_name, ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
    "            reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "            project = \"hw4p1-f24\", ### Project should be created in your wandb account\n",
    "            config  = config ### Wandb Config for your run\n",
    "        )\n",
    "\n",
    "        ### Save your model architecture as a string with str(model)\n",
    "        model_arch  = str(model)\n",
    "        ### Save it in a txt file\n",
    "        arch_file   = open(\"model_arch.txt\", \"w\")\n",
    "        file_write  = arch_file.write(model_arch)\n",
    "        arch_file.close()\n",
    "\n",
    "        ### log it in your wandb run with wandb.save()\n",
    "        # wandb.save('model_arch.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fcxKXL0hrxX"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 366228,
     "status": "error",
     "timestamp": 1728064482897,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "-pLh5_LCpVxw",
    "outputId": "2228dc6f-4b87-4eb1-8a7b-50c9c90054c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the experiments loop.\n",
    "# Each epoch wont take more than 2-3min. If its taking more time, it might be due to (but not limited to) the following:\n",
    "#   * You might be overlapping batches\n",
    "#       Eg. Input: \"I had biryani for lunch today\" and sequence length = 3,\n",
    "#           --> \"I had biryani\", \"for lunch today\" are ideal examples for inputs\n",
    "#           --> \"I had biryani\", \"had biryani for\", \"biryani for lunch\", ... is just redundant info :')\n",
    "#   * Your length calculation in the dataloader might be wrong\n",
    "# If you haven't had biryani, try it :D\n",
    "\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# %%time\n",
    "best_nll = 1e30\n",
    "for epoch in range(config['num_epochs']):\n",
    "    train_loss, curr_lr,  attn_weights = trainer.train()\n",
    "    print(attn_weights[-1].shape)\n",
    "    plot_attention(attn_weights[-1].detach().cpu().numpy())\n",
    "    visualize_attention(attn_weights)\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, prediction probabilities and generated texts for epoch \"+str(epoch+1)+\" with NLL: \"+ str(best_nll))\n",
    "\n",
    "    trainer.save()\n",
    "\n",
    "    wandb.log({\"train_loss\":train_loss,\n",
    "               \"nll\": nll,\n",
    "               \"learning_rate\": curr_lr\n",
    "              })\n",
    "    scheduler.step(nll)\n",
    "\n",
    "### Finish your wandb run\n",
    "run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "aborted",
     "timestamp": 1728064482897,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "5Oq8tLAo7jF_"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "aborted",
     "timestamp": 1728064482897,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "i_gYqXq9Jgo1"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs +1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs +1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vleoDhQe7jF_"
   },
   "source": [
    "# Evaluating generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbDQm49BKrdd"
   },
   "source": [
    " - Now that you have trained your model and got satisfactory validation NLL on the token prediction task, you can evaluate the generations you created too\n",
    " - We will use the perplexity metric to evaluate generations using a large language model available through the HuggingFace.\n",
    " - Run the bellow cell to get the perplexity.\n",
    " - You will submit this perplexity value for grading the generation component of this homework.\n",
    " - A perplexity of under **1400** will give you full credit on the generation part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvVGQNzUL3IK"
   },
   "source": [
    "### Change only the **submission_run_id**, **submission_epoch**, and **api_key** in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1728064486938,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "IV-WHyOpMW5t",
    "outputId": "67b22738-b68f-4161-84ee-5ce21b9db926"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"<YOUR TOKEN>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 9011,
     "status": "ok",
     "timestamp": 1728064549297,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "qqJ9lf7W7jF_",
    "outputId": "7e0474e9-0ac2-4939-a7de-1a53f61e2242"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THE CODE IN THIS CELL EXCEPT submission_run_id AND submission_epoch\n",
    "# PLEASE BE HONEST IN REPORTING THE PERPLEXITY VALUE!\n",
    "# WE WILL RANDOMLY CHECK SOME SUBMISSIONS USING THE SAME CODE AS THIS AND A BIG DIFFERENCE IN PERPLEXITY WILL RESULT IN AN AIV.\n",
    "\n",
    "\n",
    "# Add you submission_run_id and submission_epoch here --------------------------------------------------\n",
    "# Fill the run id and epoch number to be used for submission.\n",
    "# You will use the same run id and epoch number to generate the handin.\n",
    "\n",
    "submission_run_id = \"1728150863\" # TODO\n",
    "submission_epoch = 1 # TODO\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "n_tests = 128\n",
    "\n",
    "with open(os.path.join('hw4p1/experiments', submission_run_id, 'generated-texts-{}-test.txt'.format(submission_epoch)), 'r', encoding='utf-8') as f:\n",
    "    generated = list(f)\n",
    "\n",
    "assert len(generated) == n_tests\n",
    "for item in generated:\n",
    "    assert type(item) is str\n",
    "\n",
    "parsed_generated = []\n",
    "\n",
    "for text in generated:\n",
    "    temp = text.split(\":\")[-1].replace(\"<sos>\", \"\")\n",
    "    parsed_text = temp.replace(\" | \", \"\")\n",
    "    parsed_text = parsed_text.replace(\"<eos>\", \"\\n\")\n",
    "    parsed_generated.append(parsed_text)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_perplexity(text, model, tokenizer):\n",
    "    \"\"\"Compute the perplexity of the provided text using a Hugging Face model.\"\"\"\n",
    "    encodings = tokenizer(text, return_tensors='pt')\n",
    "    input_ids = encodings.input_ids.to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss)\n",
    "    return perplexity.item()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Define the model and tokenizer\n",
    "\n",
    "model_name = \"gpt2-medium\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=\"auto\").to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          torch_dtype=\"auto\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Calculate perplexity for each generated sequence\n",
    "perps = [calculate_perplexity(text, model, tokenizer) for text in tqdm(parsed_generated)]\n",
    "avg_perp = np.mean(perps)\n",
    "\n",
    "# Report this number when running the makefile to create the handin\n",
    "print(\"Your mean perplexity for generated sequences: {}\".format(avg_perp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBqjqy-EyU27"
   },
   "source": [
    "# Create handin\n",
    "Navigate to the handout directory to run the below cell. This command will create the handin with all the required files (including attention.py). So make sure you have the entire handout directory wherever you are running this notebook (local machine, Colab, AWS, etc.). This command requires that this completed notebook be in the hw4 folder inside the handout directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1728064664794,
     "user": {
      "displayName": "Dareen Safar B Alharthi",
      "userId": "02001227163038947109"
     },
     "user_tz": 240
    },
    "id": "hWRyPvWmgLQs"
   },
   "outputs": [],
   "source": [
    "# TODO: Generate the handin to submit to autolab\n",
    "\n",
    "# For example:\n",
    "# !make runid=1727189256 epoch=5 ppl=74.54703049361706\n",
    "\n",
    "!make runid=1728150863 epoch=1 ppl=86.18322575837374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "989a3c3836794109ac641230122845a3",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "021b42305ba8464e8fda8b9aad4d8cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d8079281af545aeb6f0575e9e3ac194",
      "max": 128,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3933d306312142d0b2530cb48749a1c5",
      "value": 128
     }
    },
    "0222b674a16d4928b6b97ea1d26e7526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd4f81c2dc924ddab0419a99c310f7bc",
      "placeholder": "​",
      "style": "IPY_MODEL_870205a586a7416b816bdbd7de80d3c6",
      "value": " 164/164 [00:30&lt;00:00,  5.34it/s]"
     }
    },
    "05f0b0b3675b4067bceeebed0eebb5e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41cb6365dbbd44b3b542ba624c27f0a9",
      "placeholder": "​",
      "style": "IPY_MODEL_46e697e7a84044898861c53c2b9ea719",
      "value": "100%"
     }
    },
    "0952ee44d5184416b11d59bdd5c8f043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9dc2a7512ba4284989b1132657d6d2c",
       "IPY_MODEL_45daf4e9346d45d1ad382c75c39621ee",
       "IPY_MODEL_b9d9b44267824c12a84575612cb66a8d"
      ],
      "layout": "IPY_MODEL_602c14b8bd57466797c0df1c19cf21b9"
     }
    },
    "0d1d85393897420f8c62fd9a2f658a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3fec01b211a4011a4139c7e49c1472e",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b91fbdae93e040ff9494009ae5f4269a",
      "value": 164
     }
    },
    "0d8079281af545aeb6f0575e9e3ac194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ed79dfc0773442d89cae81f4c5a15bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53e070fccdf84ddb9f59747b46cdcea1",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0cb6b2173a34e0fb57330fc5a4b2ad5",
      "value": 164
     }
    },
    "10031ef0e9964000a6f0a6036b9191a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29fc0f61a788497f8978c4fa64237da8",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_712004e34e2a4aaf980da8510ffc645c",
      "value": 164
     }
    },
    "14c6403d9a5b4f23bfafdb45c1ed4652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e93c403c3ff44d8989b6bbcba9269d62",
      "placeholder": "​",
      "style": "IPY_MODEL_f09f9577464c4bbb8c87beda6cfcfed7",
      "value": "100%"
     }
    },
    "16427c3273f94b23bfb6febf718096f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5ae3581e3b4221aac94e31464d45eb",
      "placeholder": "​",
      "style": "IPY_MODEL_ea9af345c9ac464b8b2f1669c1b83ad7",
      "value": " 164/164 [00:30&lt;00:00,  5.34it/s]"
     }
    },
    "16832504a4dd428bad4c0090808a0224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c3f96469a134055bba5c3111c99d5dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e82e793d108420da31ca3dd79c2fc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb19c27c6485438aa605d5916c38e1d5",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65c7fd3ea95a41ab8098f8c6a362ed7d",
      "value": 164
     }
    },
    "1f556210e1574e399794180e3c3e0687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25327d1b18d64af2877145ad487cac2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "275b2b098ada4a248e1d48bd572274b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9002f01ec3044a4e81d409f1ad1069e0",
       "IPY_MODEL_d1bf6249165a41518fa8c75961d4d917",
       "IPY_MODEL_619f016adbe84f1285050497a86e2294"
      ],
      "layout": "IPY_MODEL_3845b23a2b4d44a18657c071cc253730"
     }
    },
    "29fc0f61a788497f8978c4fa64237da8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f5ae3581e3b4221aac94e31464d45eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b2ffb042b442c398220794ce123d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3845b23a2b4d44a18657c071cc253730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3933d306312142d0b2530cb48749a1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b6d33618eac401bb9b5fdb4faf63e10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41cb6365dbbd44b3b542ba624c27f0a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "424232f50a3642cda7e5c0f9a6cedae7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "429b9dc5a5a1459a89432ddb631ab3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ca34cd8d83344db9f0e211f84b50989",
      "placeholder": "​",
      "style": "IPY_MODEL_9b9e88f7800a42ab9c2d62897b5bfa43",
      "value": " 164/164 [00:30&lt;00:00,  5.48it/s]"
     }
    },
    "45daf4e9346d45d1ad382c75c39621ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_637284e3591443e0baee989139e97e6b",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5b8f45116c44998b2bf25c45771243c",
      "value": 164
     }
    },
    "46e697e7a84044898861c53c2b9ea719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49356a63c4cc47e6b58434c58ed7d3dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3b6e41bd9f4ffa88235ffff01578cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cba506353a44070a965e33230ff08b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90f1d025ae724772950f5e07ace81ea4",
       "IPY_MODEL_0ed79dfc0773442d89cae81f4c5a15bc",
       "IPY_MODEL_0222b674a16d4928b6b97ea1d26e7526"
      ],
      "layout": "IPY_MODEL_25327d1b18d64af2877145ad487cac2a"
     }
    },
    "4ea1c94d228f4dee931f8446bb214dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a898fb6a4fb04e09b6778d40eacb1de8",
      "placeholder": "​",
      "style": "IPY_MODEL_5199055acb1042a7a11db0b4a87ae7a9",
      "value": " 164/164 [00:30&lt;00:00,  5.45it/s]"
     }
    },
    "50093409a2d14f5bbd9e014f0094e5ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75988a9551cc457ca31bfa2040a06dc0",
       "IPY_MODEL_9d612c6205d340aa98917ad08d938d92",
       "IPY_MODEL_e3329277646f42539a1b63b5436fd68b"
      ],
      "layout": "IPY_MODEL_4b3b6e41bd9f4ffa88235ffff01578cd"
     }
    },
    "5199055acb1042a7a11db0b4a87ae7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53e070fccdf84ddb9f59747b46cdcea1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c9f7ddf5ca4d8aa471bd313bcf95af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8647bf649a4b8e929f742fd1b1f0a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bae05681c0547fab2532dc3a7f52641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eac718c7762d48b5ba2b18f51c0ed344",
       "IPY_MODEL_1e82e793d108420da31ca3dd79c2fc66",
       "IPY_MODEL_b0ca6d99ce3849bfb8ad89fe7e3c8d8a"
      ],
      "layout": "IPY_MODEL_e850fa40a4db41c2be8c10e34abc22e3"
     }
    },
    "5d0de0b377064d94a1ffbbd2b7a9ed10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5de3dc562e3a4b1cb269491a7789524c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df78e23f484145498da3d6771195cd5b",
      "placeholder": "​",
      "style": "IPY_MODEL_c4b58122becb49538eaebad8ce4829eb",
      "value": "100%"
     }
    },
    "5f2ce6b1fee0476f87a684126d4973af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d49fae0373f94405bb405f4cbc4b9fbd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2f4d21250d7431b8aecc5aa10ab4e64",
      "value": 1
     }
    },
    "602c14b8bd57466797c0df1c19cf21b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "610de3af7b8e48359cf1378a30f84bbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "619f016adbe84f1285050497a86e2294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d0de0b377064d94a1ffbbd2b7a9ed10",
      "placeholder": "​",
      "style": "IPY_MODEL_35b2ffb042b442c398220794ce123d51",
      "value": " 164/164 [00:31&lt;00:00,  5.36it/s]"
     }
    },
    "61f663a4bb324f29a362f67c0cc78390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "637284e3591443e0baee989139e97e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "647faa0623b24bd98e55d4688ba7ab4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64a1d68edb9244abbcef52089a1af541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65417fb9c03b45eca1defcc840c968bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65c7fd3ea95a41ab8098f8c6a362ed7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bd958f3ff7c44be8c22a1f83548bdd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c9205ce2f354217b716bc331f9f8bea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d4736314ca14db4811d1c876ec79022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "712004e34e2a4aaf980da8510ffc645c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75988a9551cc457ca31bfa2040a06dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49356a63c4cc47e6b58434c58ed7d3dd",
      "placeholder": "​",
      "style": "IPY_MODEL_fce52753ffab44c3bf490dab97177e61",
      "value": "100%"
     }
    },
    "792870e49b7c4142990174c181fc7b64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ca34cd8d83344db9f0e211f84b50989": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8220cf848e874beb8232f8a54ff94bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b8647bf649a4b8e929f742fd1b1f0a4",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d4736314ca14db4811d1c876ec79022",
      "value": 164
     }
    },
    "83198e7d71194381a055791ee35b5513": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_424232f50a3642cda7e5c0f9a6cedae7",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e2d7b94121547179d5eb44eec4b0f49",
      "value": 164
     }
    },
    "870205a586a7416b816bdbd7de80d3c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c0f43054de3454fb230d78bda5dda3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b73e250ab1e2415c99a03e97343cc3d5",
      "placeholder": "​",
      "style": "IPY_MODEL_96cbc63130c841e0b82f474a817092e2",
      "value": " 164/164 [00:30&lt;00:00,  5.43it/s]"
     }
    },
    "8c6da83183dc41198b7559cbd5d0dc05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64a1d68edb9244abbcef52089a1af541",
      "placeholder": "​",
      "style": "IPY_MODEL_ad88579431e74f0085dc9187393ca621",
      "value": "100%"
     }
    },
    "8ee4bbe114524c708874646c760a221b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9002f01ec3044a4e81d409f1ad1069e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16832504a4dd428bad4c0090808a0224",
      "placeholder": "​",
      "style": "IPY_MODEL_dc92e06cf84042bead6399f1f00200be",
      "value": "100%"
     }
    },
    "90f1d025ae724772950f5e07ace81ea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de86935986f84bdb8868c32dcfd6e00d",
      "placeholder": "​",
      "style": "IPY_MODEL_a77270ef291a4004bdafd1c17fab8ad1",
      "value": "100%"
     }
    },
    "9461027d7dee45a79caeeb2c42d8b703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf4135ee00e3436090331216e318023f",
      "placeholder": "​",
      "style": "IPY_MODEL_1c3f96469a134055bba5c3111c99d5dd",
      "value": " 164/164 [00:30&lt;00:00,  5.40it/s]"
     }
    },
    "94ec64a7c62847c39b85544c5e51868d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96cbc63130c841e0b82f474a817092e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "975ff2c3670547f79d70838d3bf79b96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97986683f2164f4da38a77a2e0bcced1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9e88f7800a42ab9c2d62897b5bfa43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d612c6205d340aa98917ad08d938d92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9e28d150e1c4997800916ec0633e462",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61f663a4bb324f29a362f67c0cc78390",
      "value": 164
     }
    },
    "9e1f0c10b12a4ec0abb13cc3a483f368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e2d7b94121547179d5eb44eec4b0f49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a275cb39f444452db7e6481ccf2790e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2e72cc1cabf43e49b94ce1167dbd2ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05f0b0b3675b4067bceeebed0eebb5e7",
       "IPY_MODEL_0d1d85393897420f8c62fd9a2f658a99",
       "IPY_MODEL_429b9dc5a5a1459a89432ddb631ab3a2"
      ],
      "layout": "IPY_MODEL_d529c408271146479b9cb0db63fc5b31"
     }
    },
    "a453b44132404ff98876d35867b42af3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5b8f45116c44998b2bf25c45771243c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a77270ef291a4004bdafd1c17fab8ad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a898fb6a4fb04e09b6778d40eacb1de8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ace85ad458ca4d30b2aec41def390e5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad88579431e74f0085dc9187393ca621": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0ca6d99ce3849bfb8ad89fe7e3c8d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a453b44132404ff98876d35867b42af3",
      "placeholder": "​",
      "style": "IPY_MODEL_647faa0623b24bd98e55d4688ba7ab4c",
      "value": " 164/164 [00:31&lt;00:00,  5.46it/s]"
     }
    },
    "b73e250ab1e2415c99a03e97343cc3d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b91fbdae93e040ff9494009ae5f4269a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b994304b174c4f4b9cc807bb437a4ec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0094263e2a64eef9bbbb0c87f94d2bd",
       "IPY_MODEL_8220cf848e874beb8232f8a54ff94bcc",
       "IPY_MODEL_8c0f43054de3454fb230d78bda5dda3e"
      ],
      "layout": "IPY_MODEL_f1bec027748b4dc2b188e01d1b1672d2"
     }
    },
    "b9d9b44267824c12a84575612cb66a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97986683f2164f4da38a77a2e0bcced1",
      "placeholder": "​",
      "style": "IPY_MODEL_f46339e261e64d0e8ab16f0b9323c2f2",
      "value": " 164/164 [00:30&lt;00:00,  5.18it/s]"
     }
    },
    "bf4135ee00e3436090331216e318023f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f4d21250d7431b8aecc5aa10ab4e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3b67a3dac0f4e699f26b25d9ca98942": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4e71e537a6144d3ae6e0853d2a9174b",
       "IPY_MODEL_5f2ce6b1fee0476f87a684126d4973af"
      ],
      "layout": "IPY_MODEL_610de3af7b8e48359cf1378a30f84bbd"
     }
    },
    "c3d02d8668594d3e9c8abec30cc245d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b6d33618eac401bb9b5fdb4faf63e10",
      "placeholder": "​",
      "style": "IPY_MODEL_c610c942da7a458b9719f7a81e208898",
      "value": "100%"
     }
    },
    "c3fec01b211a4011a4139c7e49c1472e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42051dfdb184699864a82ecf5d7b868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bd958f3ff7c44be8c22a1f83548bdd6",
      "placeholder": "​",
      "style": "IPY_MODEL_6c9205ce2f354217b716bc331f9f8bea",
      "value": " 128/128 [00:04&lt;00:00, 33.43it/s]"
     }
    },
    "c4b58122becb49538eaebad8ce4829eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c610c942da7a458b9719f7a81e208898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c622782dfff24d948e64a23e50ae2d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5dfaebdd2044c12b9009864c6256724",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65417fb9c03b45eca1defcc840c968bd",
      "value": 164
     }
    },
    "c63030c0ec9d40ba95822651b8997edb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0f92caee314e4ab7b4920749d5a051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5f06c44f5848889d4560c8c194f506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1bf6249165a41518fa8c75961d4d917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_792870e49b7c4142990174c181fc7b64",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb5f06c44f5848889d4560c8c194f506",
      "value": 164
     }
    },
    "d49fae0373f94405bb405f4cbc4b9fbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d529c408271146479b9cb0db63fc5b31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5dfaebdd2044c12b9009864c6256724": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d96a705b0f7d492daacfd417f396382f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5de3dc562e3a4b1cb269491a7789524c",
       "IPY_MODEL_83198e7d71194381a055791ee35b5513",
       "IPY_MODEL_4ea1c94d228f4dee931f8446bb214dda"
      ],
      "layout": "IPY_MODEL_e52eea491a4748a5a8ea2fb25774dc2d"
     }
    },
    "dc92e06cf84042bead6399f1f00200be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcb8989b27cb4ffa802e7ca5571886f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14c6403d9a5b4f23bfafdb45c1ed4652",
       "IPY_MODEL_10031ef0e9964000a6f0a6036b9191a7",
       "IPY_MODEL_16427c3273f94b23bfb6febf718096f2"
      ],
      "layout": "IPY_MODEL_a275cb39f444452db7e6481ccf2790e5"
     }
    },
    "de86935986f84bdb8868c32dcfd6e00d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df78e23f484145498da3d6771195cd5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0094263e2a64eef9bbbb0c87f94d2bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56c9f7ddf5ca4d8aa471bd313bcf95af",
      "placeholder": "​",
      "style": "IPY_MODEL_94ec64a7c62847c39b85544c5e51868d",
      "value": "100%"
     }
    },
    "e308ddfdfb244facb54b4f4372da1615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3329277646f42539a1b63b5436fd68b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca0f92caee314e4ab7b4920749d5a051",
      "placeholder": "​",
      "style": "IPY_MODEL_1f556210e1574e399794180e3c3e0687",
      "value": " 164/164 [00:30&lt;00:00,  5.37it/s]"
     }
    },
    "e52eea491a4748a5a8ea2fb25774dc2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e850fa40a4db41c2be8c10e34abc22e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e93c403c3ff44d8989b6bbcba9269d62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9e28d150e1c4997800916ec0633e462": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea9af345c9ac464b8b2f1669c1b83ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eac718c7762d48b5ba2b18f51c0ed344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_975ff2c3670547f79d70838d3bf79b96",
      "placeholder": "​",
      "style": "IPY_MODEL_8ee4bbe114524c708874646c760a221b",
      "value": "100%"
     }
    },
    "eb19c27c6485438aa605d5916c38e1d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f09f9577464c4bbb8c87beda6cfcfed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0cb6b2173a34e0fb57330fc5a4b2ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1bec027748b4dc2b188e01d1b1672d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3125a31240f4cc28493b3fb996ec29f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c6da83183dc41198b7559cbd5d0dc05",
       "IPY_MODEL_021b42305ba8464e8fda8b9aad4d8cce",
       "IPY_MODEL_c42051dfdb184699864a82ecf5d7b868"
      ],
      "layout": "IPY_MODEL_fbb23c4c010848849a43ec3d5d23d4d1"
     }
    },
    "f46339e261e64d0e8ab16f0b9323c2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4e71e537a6144d3ae6e0853d2a9174b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c63030c0ec9d40ba95822651b8997edb",
      "placeholder": "​",
      "style": "IPY_MODEL_e308ddfdfb244facb54b4f4372da1615",
      "value": "0.012 MB of 0.012 MB uploaded\r"
     }
    },
    "f5bf0c94a36f4011800f1fb9f159fb3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9dc2a7512ba4284989b1132657d6d2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ace85ad458ca4d30b2aec41def390e5c",
      "placeholder": "​",
      "style": "IPY_MODEL_9e1f0c10b12a4ec0abb13cc3a483f368",
      "value": "100%"
     }
    },
    "fb3c576b5048430f94732dbbdfd033e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3d02d8668594d3e9c8abec30cc245d6",
       "IPY_MODEL_c622782dfff24d948e64a23e50ae2d9a",
       "IPY_MODEL_9461027d7dee45a79caeeb2c42d8b703"
      ],
      "layout": "IPY_MODEL_f5bf0c94a36f4011800f1fb9f159fb3a"
     }
    },
    "fbb23c4c010848849a43ec3d5d23d4d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fce52753ffab44c3bf490dab97177e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd4f81c2dc924ddab0419a99c310f7bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
